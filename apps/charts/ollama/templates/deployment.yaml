apiVersion: apps/v1
kind: Deployment
metadata:
  name: "{{ .Release.Name }}"
spec:
  strategy:
    type: RollingUpdate
  replicas: 1
  revisionHistoryLimit: 0
  selector:
    matchLabels:
      app: "{{ .Release.Name }}"
  template:
    metadata:
      labels:
        app: "{{ .Release.Name }}"
    spec:
      containers:
        - name: "{{ .Release.Name }}"
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: "{{ .Values.image.pullPolicy }}"
          env:
          - name: OLLAMA_INTEL_GPU
            value: "true"
          resources:
            limits:
              gpu.intel.com/i915: "1"
            requests:
              gpu.intel.com/i915: "1"
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          livenessProbe:
            tcpSocket:
              port: http
          readinessProbe:
            tcpSocket:
              port: http
          volumeMounts:
            - mountPath: /root/.ollama
              name: data

      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: "{{ .Release.Name }}-data"
